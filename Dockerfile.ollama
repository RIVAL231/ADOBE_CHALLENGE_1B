# Stage 1: Download the Ollama model
FROM ollama/ollama AS model-downloader

# Start ollama server in background and pull the model
RUN ollama serve & \
    sleep 10 && \
    ollama pull gemma3:1b && \
    pkill ollama

# Stage 2: Build the final Ollama container with the pre-downloaded model
FROM ollama/ollama

# Set the OLLAMA_HOST environment variable for accessibility
ENV OLLAMA_HOST "0.0.0.0"

# Copy the downloaded model from the first stage to the final container
# Ollama stores models in /root/.ollama/models by default
COPY --from=model-downloader /root/.ollama /root/.ollama

# Expose the default Ollama port
EXPOSE 11434

# Command to run Ollama when the container starts
CMD ["ollama", "serve"]
